{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdbcca6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote Streamlit app to: C:\\Users\\UserAdmin\\Desktop\\5126final\\slit\\app.py\n"
     ]
    }
   ],
   "source": [
    "# This cell writes a standalone Streamlit app to app.py in the same folder as this notebook.\n",
    "# Run this cell once, then launch the app from PowerShell with:\n",
    "#   streamlit run .\\app.py\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "APP_CODE = r'''\n",
    "\"\"\"\n",
    "Streamlit app for predicting with a pre-trained Random Forest pipeline.\n",
    "This version does NOT require a CSV upload. Instead, it shows input fields for selected top features\n",
    "listed in rf_top20.csv (first column). Remaining features are left blank and imputed by the pipeline.\n",
    "It also introspects the saved model to ensure all required input columns exist, preventing 'columns are missing' errors.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "\n",
    "# Compatibility shim for pickled sklearn pipelines that reference private internals\n",
    "try:\n",
    "    # If available, this import will satisfy unpickling\n",
    "    from sklearn.compose._column_transformer import _RemainderColsList  # type: ignore[attr-defined]\n",
    "except Exception:\n",
    "    # If import fails (version mismatch), inject a dummy into the module so pickle can resolve it\n",
    "    try:\n",
    "        import sklearn.compose._column_transformer as _ct  # type: ignore\n",
    "\n",
    "        class _RemainderColsList(list):\n",
    "            pass\n",
    "\n",
    "        _ct._RemainderColsList = _RemainderColsList  # type: ignore[attr-defined]\n",
    "    except Exception:\n",
    "        # As a last resort, continue; joblib.load may still succeed for some artifacts\n",
    "        pass\n",
    "\n",
    "# Artifact paths (same folder as this script)\n",
    "ARTIFACT_DIR = Path(__file__).parent\n",
    "MODEL_PATH = ARTIFACT_DIR / \"rf_pipeline.joblib\"\n",
    "META_PATH = ARTIFACT_DIR / \"rf_meta.json\"\n",
    "TOP20_PATH = ARTIFACT_DIR / \"rf_top20.csv\"\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    try:\n",
    "        return joblib.load(MODEL_PATH)\n",
    "    except Exception as e:\n",
    "        st.error(\n",
    "            f\"Failed to load model artifact '{MODEL_PATH.name}'. Ensure the file exists and sklearn versions are compatible. Details: {e}\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_meta():\n",
    "    try:\n",
    "        with open(META_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        # Metadata is optional (only used for target column name); warn but continue\n",
    "        st.warning(\n",
    "            f\"Could not load metadata file '{META_PATH.name}'. Using default target column name. Details: {e}\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_top20_features():\n",
    "    \"\"\"\n",
    "    Read rf_top20.csv directly: use the first column as feature names.\n",
    "    Returns: list[str] of feature names (could be engineered/one-hot names).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(TOP20_PATH)\n",
    "        if df.empty:\n",
    "            st.error(f\"'{TOP20_PATH.name}' is empty.\")\n",
    "            return None\n",
    "        # Use the first column directly as feature names\n",
    "        features = df.iloc[:, 0].astype(str).dropna().tolist()\n",
    "        if not features:\n",
    "            st.error(f\"No feature names found in '{TOP20_PATH.name}'.\")\n",
    "            return None\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        st.error(f\"Failed to load top-20 features from '{TOP20_PATH.name}'. Details: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "_NUMERIC_SUFFIX_RE = re.compile(r\"^-?\\d+(?:\\.\\d+)?$\")\n",
    "\n",
    "def to_base_feature_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert a possibly one-hot feature name like\n",
    "      \"Q273: Marital status_6.0\" -> \"Q273: Marital status\"\n",
    "    Heuristic: if there's an underscore and the last token looks numeric (code/category),\n",
    "    drop the suffix. Otherwise, keep as-is.\n",
    "    \"\"\"\n",
    "    if \"_\" in name:\n",
    "        left, right = name.rsplit(\"_\", 1)\n",
    "        if _NUMERIC_SUFFIX_RE.match(right.strip()):\n",
    "            return left.strip()\n",
    "    return name.strip()\n",
    "\n",
    "def derive_raw_features_from_top20(top20: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Derive raw/base column names expected in the uploaded CSV from top20 list.\n",
    "    This collapses engineered one-hot names back to their source column names,\n",
    "    preserving order and uniqueness.\n",
    "    \"\"\"\n",
    "    seen = OrderedDict()\n",
    "    for f in top20:\n",
    "        base = to_base_feature_name(str(f))\n",
    "        if base not in seen:\n",
    "            seen[base] = True\n",
    "    return list(seen.keys())\n",
    "\n",
    "def is_probably_numeric(col_name: str) -> bool:\n",
    "    hint = col_name.lower()\n",
    "    patterns = [\n",
    "        \"age\", \"year\", \"number\", \"count\", \"latitude\", \"longitude\", \"income\", \"amount\", \"score\", \"height\", \"weight\"\n",
    "    ]\n",
    "    return any(p in hint for p in patterns)\n",
    "\n",
    "def coerce_value(name: str, s: str):\n",
    "    s = (s or \"\").strip()\n",
    "    if s == \"\":\n",
    "        return None\n",
    "    if is_probably_numeric(name):\n",
    "        try:\n",
    "            return float(s)\n",
    "        except Exception:\n",
    "            st.warning(f\"Could not parse a numeric value for '{name}'. Treating as missing.\")\n",
    "            return None\n",
    "    return s\n",
    "\n",
    "def infer_required_input_columns(model) -> list[str] | None:\n",
    "    \"\"\"\n",
    "    Try to infer the raw input column names the model expects when calling predict(X as DataFrame).\n",
    "    Prefer the sklearn-wide attribute `feature_names_in_`. Fallback to common pipeline patterns.\n",
    "    \"\"\"\n",
    "    # Primary: most sklearn estimators/pipelines expose feature_names_in_ after fit when trained on DataFrame\n",
    "    cols = getattr(model, \"feature_names_in_\", None)\n",
    "    if cols is not None:\n",
    "        return list(cols)\n",
    "    # Pipeline fallback: look for a 'pre' or 'preprocessor' step with feature_names_in_'\n",
    "    pre = None\n",
    "    for key in (\"pre\", \"preprocessor\"):\n",
    "        try:\n",
    "            pre = model.named_steps.get(key)  # type: ignore[attr-defined]\n",
    "            if pre is not None:\n",
    "                break\n",
    "        except Exception:\n",
    "            pass\n",
    "    if pre is not None:\n",
    "        cols = getattr(pre, \"feature_names_in_\", None)\n",
    "        if cols is not None:\n",
    "            return list(cols)\n",
    "    return None\n",
    "\n",
    "def pretty_label(eng_name: str, raw_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Make a human-friendly label. Special-case marital status to 'Marital Status'.\n",
    "    Otherwise: strip leading 'Q123: ' and remove trailing encoded suffix from engineered name.\n",
    "    \"\"\"\n",
    "    low = eng_name.lower()\n",
    "    if \"marital status\" in low:\n",
    "        return \"Marital Status\"\n",
    "    # generic cleanup\n",
    "    label = eng_name\n",
    "    if \":\" in label:\n",
    "        label = label.split(\":\", 1)[1].strip()\n",
    "    if \"_\" in label:\n",
    "        label = label.rsplit(\"_\", 1)[0]\n",
    "    return label or raw_name\n",
    "\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"Expected No. of Children â€“ Predictor\", page_icon=\"ðŸ‘¶\", layout=\"wide\")\n",
    "\n",
    "    # Global CSS to polish look & feel\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "        <style>\n",
    "        .main .block-container { padding-top: 2rem; padding-bottom: 2rem; }\n",
    "        h1, h2, h3 { font-weight: 700; }\n",
    "        .stSelectbox label, .stTextInput label { font-weight: 600; }\n",
    "        .stButton>button {\n",
    "            background: #4f46e5; color: #ffffff;\n",
    "            padding: 0.6rem 1rem; border-radius: 8px; border: 1px solid transparent;\n",
    "        }\n",
    "        .stButton>button:hover { background: #4338ca; }\n",
    "        .metric-card {\n",
    "            background: linear-gradient(135deg, #f8fafc 0%, #eef2ff 100%);\n",
    "            border: 1px solid #e5e7eb; border-radius: 16px; padding: 24px;\n",
    "            box-shadow: 0 1px 3px rgba(0,0,0,0.06);\n",
    "        }\n",
    "        .metric-value {\n",
    "            font-size: 56px; font-weight: 800; line-height: 1; color: #111827;\n",
    "        }\n",
    "        .metric-sub { color: #6b7280; margin-bottom: 6px; }\n",
    "        </style>\n",
    "        \"\"\",\n",
    "        unsafe_allow_html=True,\n",
    "    )\n",
    "\n",
    "    st.title(\"ðŸ‘¶ Expected No. of Children â€“ Predictor\")\n",
    "    st.caption(\"Enter values for a few of the most important features.\")\n",
    "\n",
    "    # Sidebar with quick info\n",
    "    with st.sidebar:\n",
    "        st.header(\"About\")\n",
    "        st.markdown(\n",
    "            \"This app uses a pre-trained Random Forest pipeline and the top features from rf_top20.csv to make a prediction.\"\n",
    "        )\n",
    "        st.divider()\n",
    "        st.subheader(\"Artifacts\")\n",
    "        for p in (MODEL_PATH, TOP20_PATH, META_PATH):\n",
    "            exists = p.exists()\n",
    "            emoji = \"âœ…\" if exists else \"âŒ\"\n",
    "            st.write(f\"{emoji} {p.name}\")\n",
    "\n",
    "    model = load_model()\n",
    "    meta = load_meta()  # optional\n",
    "\n",
    "    if model is None:\n",
    "        st.stop()\n",
    "\n",
    "    # Load top-20 features from CSV (post-encoding names are possible)\n",
    "    top20_features = load_top20_features()\n",
    "    if not top20_features:\n",
    "        st.stop()\n",
    "\n",
    "    # Exclude engineered features we don't want in the UI (case-insensitive)\n",
    "    excluded_phrases = [\"year of birth\"]\n",
    "    filtered_engineered = [f for f in top20_features if all(p not in f.lower() for p in excluded_phrases)]\n",
    "    # Pick top-5 after exclusion (backfill with next features)\n",
    "    top_engineered = filtered_engineered[:5]\n",
    "\n",
    "    # Derive full raw feature list from the top-20 (for display; may be narrower or wider than model's actual requirement)\n",
    "    raw_features_from_top20 = derive_raw_features_from_top20(top20_features)\n",
    "\n",
    "    # Infer the model's required raw input columns (best-effort)\n",
    "    required_cols = infer_required_input_columns(model)\n",
    "    if required_cols is None:\n",
    "        # Fallback: assume raw columns are those derived from top-20 (may still fail if model expects more)\n",
    "        required_cols = raw_features_from_top20\n",
    "        # Hidden info message previously shown to user is now suppressed.\n",
    "\n",
    "\n",
    "    # Map engineered -> raw for the selected inputs\n",
    "    mapping = {eng: to_base_feature_name(eng) for eng in top_engineered}\n",
    "\n",
    "    # Decide target column name from metadata if available (kept for internal reference),\n",
    "    # but display the prediction as 'Expected No. of Children'.\n",
    "    if isinstance(meta, dict):\n",
    "        target_column = meta.get(\"target_column\", \"prediction\")\n",
    "    else:\n",
    "        target_column = \"prediction\"\n",
    "    display_label = \"Expected No. of Children\"\n",
    "\n",
    "    st.subheader(\"Input values\")\n",
    "    with st.form(\"predict_form\"):\n",
    "        inputs_raw = {}\n",
    "        display_labels = {}\n",
    "        cols = st.columns(min(3, len(mapping)) or 1)\n",
    "        for idx, (eng, raw) in enumerate(mapping.items()):\n",
    "            col = cols[idx % len(cols)]\n",
    "            with col:\n",
    "                label = pretty_label(eng, raw)\n",
    "                display_labels[raw] = label\n",
    "                low_eng = eng.lower()\n",
    "                low_raw = raw.lower()\n",
    "                if \"marital status\" in low_eng:\n",
    "                    # Labeled dropdown for marital status while storing numeric code\n",
    "                    options = [\n",
    "                        (1, \"Married\"),\n",
    "                        (2, \"Living together as married\"),\n",
    "                        (3, \"Divorced\"),\n",
    "                        (4, \"Separated\"),\n",
    "                        (5, \"Widowed\"),\n",
    "                        (6, \"Single\"),\n",
    "                    ]\n",
    "                    sel = st.selectbox(\n",
    "                        label,\n",
    "                        options=options,\n",
    "                        index=None,\n",
    "                        placeholder=\"Select marital status\",\n",
    "                        format_func=lambda x: f\"{x[0]}. {x[1]}\"\n",
    "                    )\n",
    "                    inputs_raw[raw] = float(sel[0]) if sel is not None else None\n",
    "                elif (\"live with your parents\" in low_eng) or (\"live with your parents\" in low_raw) or ((\"live with\" in low_eng and \"parent\" in low_eng) or (\"live with\" in low_raw and \"parent\" in low_raw)):\n",
    "                    # Labeled dropdown for 'Do you live with your parents?' mapping to numeric code\n",
    "                    options = [\n",
    "                        (1, \"No\"),\n",
    "                        (2, \"Yes, own parent(s)\"),\n",
    "                        (3, \"Yes, parent(s) in law\"),\n",
    "                        (4, \"Yes, both own parent(s) and parent(s) in law\"),\n",
    "                    ]\n",
    "                    sel = st.selectbox(\n",
    "                        label,\n",
    "                        options=options,\n",
    "                        index=None,\n",
    "                        placeholder=\"Select an option\",\n",
    "                        format_func=lambda x: f\"{x[0]}. {x[1]}\"\n",
    "                    )\n",
    "                    inputs_raw[raw] = float(sel[0]) if sel is not None else None\n",
    "                elif (\"sex before marriage\" in low_eng) or (\"sex before marriage\" in low_raw) or ((\"justifiable\" in low_eng and \"sex\" in low_eng) or (\"justifiable\" in low_raw and \"sex\" in low_raw)):\n",
    "                    # Labeled dropdown for 'Justifiable sex before marriage' on a 1â€“10 scale with explicit labels\n",
    "                    options = [\n",
    "                        (1, \"1.- Never justifiable\"),\n",
    "                        (2, \"2.- 2\"),\n",
    "                        (3, \"3.- 3\"),\n",
    "                        (4, \"4.- 4\"),\n",
    "                        (5, \"5.- 5\"),\n",
    "                        (6, \"6.- 6\"),\n",
    "                        (7, \"7.- 7\"),\n",
    "                        (8, \"8.- 8\"),\n",
    "                        (9, \"9.- 9\"),\n",
    "                        (10, \"10.- Always justifiable\"),\n",
    "                    ]\n",
    "                    sel = st.selectbox(\n",
    "                        \"Justifiable Sex Before Marriage\",\n",
    "                        options=options,\n",
    "                        index=None,\n",
    "                        placeholder=\"Select a value 1â€“10\",\n",
    "                        format_func=lambda x: x[1]\n",
    "                    )\n",
    "                    inputs_raw[raw] = float(sel[0]) if sel is not None else None\n",
    "                elif (\"number of people in household\" in low_eng) or (\"number of people in household\" in low_raw) or ((\"household\" in low_eng and \"people\" in low_eng) or (\"household\" in low_raw and \"people\" in low_raw)) or (\"household size\" in low_eng) or (\"household size\" in low_raw):\n",
    "                    # Labeled dropdown for 'Number of people in household'\n",
    "                    options = [\n",
    "                        (1, \"1 Person\"),\n",
    "                        (2, \"2 Persons\"),\n",
    "                        (3, \"3 Persons\"),\n",
    "                        (4, \"4 Persons\"),\n",
    "                        (5, \"5 Persons\"),\n",
    "                        (6, \"6 Persons\"),\n",
    "                        (7, \"7 Persons or more\"),\n",
    "                    ]\n",
    "                    sel = st.selectbox(\n",
    "                        label,\n",
    "                        options=options,\n",
    "                        index=None,\n",
    "                        placeholder=\"Select household size\",\n",
    "                        format_func=lambda x: f\"{x[0]}. {x[1]}\"\n",
    "                    )\n",
    "                    inputs_raw[raw] = float(sel[0]) if sel is not None else None\n",
    "                elif (\"age\" in low_eng) or (\"age\" in low_raw):\n",
    "                    # Age selection: allow choosing from 20 to 49\n",
    "                    sel = st.selectbox(label, options=list(range(20, 50)), index=None, placeholder=\"Select age 20-49\")\n",
    "                    inputs_raw[raw] = float(sel) if sel is not None else None\n",
    "                else:\n",
    "                    placeholder = \"Leave blank to let model impute\"\n",
    "                    if eng != raw:\n",
    "                        placeholder += f\" (enter category/code for '{raw}')\"\n",
    "                    val_str = st.text_input(label, placeholder=placeholder)\n",
    "                    inputs_raw[raw] = coerce_value(raw, val_str)\n",
    "\n",
    "        submitted = st.form_submit_button(\"Predict\")\n",
    "\n",
    "    if submitted:\n",
    "        # Validate: prompt user if any fields are blank\n",
    "        missing = [display_labels.get(raw, raw) for raw, val in inputs_raw.items() if (val is None or (isinstance(val, str) and str(val).strip() == \"\"))]\n",
    "        if missing:\n",
    "            st.warning(\"Some inputs are missing. Please fill all fields before predicting.\")\n",
    "            st.markdown(\"\\n\".join([f\"- {m}\" for m in missing]))\n",
    "            st.stop()\n",
    "\n",
    "        # Build a single-row input with ALL columns the model expects, default to None\n",
    "        row = {col_name: None for col_name in required_cols}\n",
    "        # Fill provided inputs (only where the raw column exists)\n",
    "        for raw, val in inputs_raw.items():\n",
    "            if raw in row:\n",
    "                row[raw] = val\n",
    "        X = pd.DataFrame([row], columns=required_cols)\n",
    "\n",
    "        # Predict. If model is a full sklearn Pipeline, it will handle preprocessing internally.\n",
    "        try:\n",
    "            predictions = model.predict(X)\n",
    "        except Exception as e:\n",
    "            st.error(\n",
    "                \"Prediction failed. The saved artifact may not be a full preprocessing pipeline, \",\n",
    "                \"or it expects columns that cannot be imputed. \",\n",
    "            )\n",
    "            st.exception(e)\n",
    "            return\n",
    "\n",
    "        # Present the prediction in a styled, centered card\n",
    "        try:\n",
    "            pred_value = float(predictions[0])\n",
    "        except Exception:\n",
    "            pred_value = float(pd.Series(predictions).iloc[0])\n",
    "        left, center, right = st.columns([1, 2, 1])\n",
    "        with center:\n",
    "            st.markdown(\n",
    "                f\"\"\"\n",
    "                <div class='metric-card' style='text-align:center;'>\n",
    "                    <div class='metric-sub'>{display_label}</div>\n",
    "                    <div class='metric-value'>{pred_value:.1f}</div>\n",
    "                </div>\n",
    "                \"\"\",\n",
    "                unsafe_allow_html=True,\n",
    "            )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "# Write the file next to this notebook\n",
    "base_dir = Path.cwd()\n",
    "app_path = base_dir / 'app.py'\n",
    "app_path.write_text(APP_CODE, encoding='utf-8')\n",
    "print(f\"Wrote Streamlit app to: {app_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b484fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''NOT IN USE\n",
    "\n",
    "NOT IN USE\n",
    "NOT IN USE\n",
    "NOT IN USE\n",
    "NOT IN USE\n",
    "NOT IN USE\n",
    "NOT IN USE\n",
    "NOT IN USE\n",
    "NOT IN USE\n",
    "NOT IN USE\n",
    "NOT IN USE\n",
    "\n",
    "\n",
    "# Training scaffold: train a regression model to predict number of children using the top-20-derived raw features.\n",
    "# 1) Set TRAIN_CSV_PATH and TARGET_COLUMN below.\n",
    "# 2) Run this cell to produce rf_pipeline.joblib, rf_meta.json, rf_top20.csv next to the notebook.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import joblib\n",
    "\n",
    "# ------------------ USER SETTINGS ------------------\n",
    "# Point to your training data CSV (must contain raw input columns and the target column)\n",
    "TRAIN_CSV_PATH = Path(r\"path\\to\\your_training_data.csv\")  # TODO: change this\n",
    "TARGET_COLUMN = \"children_count\"  # TODO: change to your target column name\n",
    "\n",
    "# Where to write artifacts\n",
    "ARTIFACT_DIR = Path.cwd()\n",
    "MODEL_PATH = ARTIFACT_DIR / \"rf_pipeline.joblib\"\n",
    "META_PATH = ARTIFACT_DIR / \"rf_meta.json\"\n",
    "TOP20_PATH = ARTIFACT_DIR / \"rf_top20.csv\"\n",
    "\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# Load the top-20 list (engineered names possible) and derive raw/base feature names\n",
    "def load_top20_raw(artifacts_dir: Path) -> list[str]:\n",
    "    top20_path = artifacts_dir / \"rf_top20.csv\"\n",
    "    df = pd.read_csv(top20_path)\n",
    "    features = df.iloc[:, 0].astype(str).dropna().tolist()\n",
    "    # collapse engineered one-hot names into raw/base names\n",
    "    _NUMERIC_SUFFIX_RE = re.compile(r\"^-?\\d+(?:\\.\\d+)?$\")\n",
    "    def to_base(name: str) -> str:\n",
    "        if \"_\" in name:\n",
    "            left, right = name.rsplit(\"_\", 1)\n",
    "            if _NUMERIC_SUFFIX_RE.match(right.strip()):\n",
    "                return left.strip()\n",
    "        return name.strip()\n",
    "    seen = OrderedDict()\n",
    "    for f in features:\n",
    "        base = to_base(f)\n",
    "        if base not in seen:\n",
    "            seen[base] = True\n",
    "    return list(seen.keys())\n",
    "\n",
    "# Create OneHotEncoder compatible across sklearn versions\n",
    "def make_ohe():\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)  # sklearn >=1.2\n",
    "    except TypeError:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)  # older sklearn\n",
    "\n",
    "# Compute transformed feature names after fitting the preprocessing\n",
    "def get_transformed_feature_names(preprocessor: ColumnTransformer, numeric_cols: list[str], categorical_cols: list[str]) -> list[str]:\n",
    "    feature_names: list[str] = []\n",
    "    # numeric columns pass through with their original names (imputer doesn't change names)\n",
    "    feature_names.extend(numeric_cols)\n",
    "    # categorical columns use OHE feature names\n",
    "    cat_transformer = preprocessor.named_transformers_.get(\"cat\")\n",
    "    ohe = None\n",
    "    from sklearn.pipeline import Pipeline as SkPipeline\n",
    "    if isinstance(cat_transformer, SkPipeline):\n",
    "        ohe = cat_transformer.named_steps.get(\"onehot\")\n",
    "    else:\n",
    "        ohe = cat_transformer\n",
    "    if hasattr(ohe, \"get_feature_names_out\") and categorical_cols:\n",
    "        feature_names.extend(ohe.get_feature_names_out(categorical_cols).tolist())\n",
    "    return feature_names\n",
    "\n",
    "# Train pipeline and write artifacts\n",
    "def train_and_save(train_csv: Path, target_col: str):\n",
    "    if not train_csv.exists():\n",
    "        raise FileNotFoundError(f\"Training CSV not found: {train_csv}\")\n",
    "    df = pd.read_csv(train_csv)\n",
    "    # Load raw features derived from top-20 file present in ARTIFACT_DIR (or derive from your own list)\n",
    "    raw_features = load_top20_raw(ARTIFACT_DIR)\n",
    "    # Validate columns\n",
    "    missing = [c for c in raw_features + [target_col] if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in training data: {missing}\")\n",
    "\n",
    "    X = df[raw_features].copy()\n",
    "    y = df[target_col].astype(float)  # ensure numeric target\n",
    "\n",
    "    # Split for quick evaluation\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Simple type-based split; adjust if some numeric-coded columns are actually categorical\n",
    "    numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = [c for c in X_train.columns if c not in numeric_cols]\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    ])\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", make_ohe()),\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_cols),\n",
    "            (\"cat\", categorical_transformer, categorical_cols),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "\n",
    "    pipe = Pipeline(steps=[(\"pre\", preprocessor), (\"model\", model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate quickly\n",
    "    preds = pipe.predict(X_valid)\n",
    "    mae = mean_absolute_error(y_valid, preds)\n",
    "    rmse = mean_squared_error(y_valid, preds, squared=False)\n",
    "    print({\"MAE\": mae, \"RMSE\": rmse})\n",
    "\n",
    "    # After fitting, get transformed feature names and importances\n",
    "    pre = pipe.named_steps[\"pre\"]\n",
    "    feature_names = get_transformed_feature_names(pre, numeric_cols, categorical_cols)\n",
    "    importances = pipe.named_steps[\"model\"].feature_importances_\n",
    "    # Align lengths just in case\n",
    "    k = min(len(feature_names), len(importances))\n",
    "    feature_names = feature_names[:k]\n",
    "    importances = importances[:k]\n",
    "\n",
    "    # Top-20 engineered feature names by importance\n",
    "    import numpy as _np\n",
    "    order = _np.argsort(importances)[::-1]\n",
    "    top20_names = [feature_names[i] for i in order[:20]]\n",
    "    pd.DataFrame({\"feature\": top20_names}).to_csv(TOP20_PATH, index=False)\n",
    "    print(f\"Wrote top-20 feature list to: {TOP20_PATH}\")\n",
    "\n",
    "    # Save model pipeline\n",
    "    joblib.dump(pipe, MODEL_PATH)\n",
    "    print(f\"Wrote model pipeline to: {MODEL_PATH}\")\n",
    "\n",
    "    # Save meta\n",
    "    with open(META_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"target_column\": target_col}, f)\n",
    "    print(f\"Wrote meta to: {META_PATH}\")\n",
    "\n",
    "# Run training\n",
    "# Uncomment the next line after setting TRAIN_CSV_PATH and TARGET_COLUMN\n",
    "# train_and_save(TRAIN_CSV_PATH, TARGET_COLUMN)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
